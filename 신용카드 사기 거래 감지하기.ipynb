{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>284315</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>492</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target   Count  Percent(%)\n",
       "0       0  284315       99.83\n",
       "1       1     492        0.17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = data['Class'].value_counts().to_frame().reset_index()\n",
    "tmp['Percent(%)'] = tmp[\"Class\"].apply(lambda x : round(100*float(x) / len(data), 2))\n",
    "tmp = tmp.rename(columns = {\"index\" : \"Target\", \"Class\" : \"Count\"})\n",
    "\n",
    "tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               V1         V2        V3        V4        V5        V6  \\\n",
      "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
      "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
      "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
      "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
      "...           ...        ...       ...       ...       ...       ...   \n",
      "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
      "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
      "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
      "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
      "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
      "\n",
      "              V7        V8        V9       V10       V11       V12       V13  \\\n",
      "0       0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390   \n",
      "1      -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095   \n",
      "2       0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293   \n",
      "3       0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757   \n",
      "4       0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "284802 -4.918215  7.305334  1.914428  4.356170 -1.593105  2.711941 -0.689256   \n",
      "284803  0.024330  0.294869  0.584800 -0.975926 -0.150189  0.915802  1.214756   \n",
      "284804 -0.296827  0.708417  0.432454 -0.484782  0.411614  0.063119 -0.183699   \n",
      "284805 -0.686180  0.679145  0.392087 -0.399126 -1.933849 -0.962886 -1.042082   \n",
      "284806  1.577006 -0.414650  0.486180 -0.915427 -1.040458 -0.031513 -0.188093   \n",
      "\n",
      "             V14       V15       V16       V17       V18       V19       V20  \\\n",
      "0      -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412   \n",
      "1      -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083   \n",
      "2      -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980   \n",
      "3      -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038   \n",
      "4      -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "284802  4.626942 -0.924459  1.107641  1.991691  0.510632 -0.682920  1.475829   \n",
      "284803 -0.675143  1.164931 -0.711757 -0.025693 -1.221179 -1.545556  0.059616   \n",
      "284804 -0.510602  1.329284  0.140716  0.313502  0.395652 -0.577252  0.001396   \n",
      "284805  0.449624  1.962563 -0.608577  0.509928  1.113981  2.897849  0.127434   \n",
      "284806 -0.084316  0.041333 -0.302620 -0.660377  0.167430 -0.256117  0.382948   \n",
      "\n",
      "             V21       V22       V23       V24       V25       V26       V27  \\\n",
      "0      -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558   \n",
      "1      -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983   \n",
      "2       0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353   \n",
      "3      -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723   \n",
      "4      -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "284802  0.213454  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651   \n",
      "284803  0.214205  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472   \n",
      "284804  0.232045  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455   \n",
      "284805  0.265245  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821   \n",
      "284806  0.261057  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415   \n",
      "\n",
      "             V28  \n",
      "0      -0.021053  \n",
      "1       0.014724  \n",
      "2      -0.059752  \n",
      "3       0.061458  \n",
      "4       0.215153  \n",
      "...          ...  \n",
      "284802  0.823731  \n",
      "284803 -0.053527  \n",
      "284804 -0.026561  \n",
      "284805  0.104533  \n",
      "284806  0.013649  \n",
      "\n",
      "[284807 rows x 28 columns]\n",
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "284802    0\n",
      "284803    0\n",
      "284804    0\n",
      "284805    0\n",
      "284806    0\n",
      "Name: Class, Length: 284807, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_data=data.loc[:,'V1':\"V28\"]\n",
    "y_data=data.loc[:,'Class']\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 28)\n",
      "(199364,)\n",
      "(85443, 28)\n",
      "(85443,)\n"
     ]
    }
   ],
   "source": [
    "shaffle_index=np.random.permutation(len(data))#무작위배열을만들어줍니다\n",
    "x_data=x_data.values[shaffle_index]\n",
    "y_data=y_data.values[shaffle_index]\n",
    "n_train=int(len(x_data)*0.7)\n",
    "x_train=x_data[:n_train]\n",
    "y_train=y_data[:n_train]\n",
    "x_test=x_data[n_train:]\n",
    "y_test=y_data[n_train:]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 (non-fraud)</th>\n",
       "      <td>199025</td>\n",
       "      <td>85290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 (fraud)</th>\n",
       "      <td>339</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train   test\n",
       "0 (non-fraud)  199025  85290\n",
       "1 (fraud)         339    153"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[sum(y_train == 0), sum(y_test == 0)], [sum(y_train == 1), sum(y_test == 1)]], \n",
    "             columns=['train', 'test'], index=['0 (non-fraud)', '1 (fraud)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# modeling\n",
    "model_rf = RandomForestClassifier(n_estimators = 15)\n",
    "# train\n",
    "model_rf.fit(x_train, y_train)\n",
    "# predict\n",
    "y_pred = model_rf.predict(x_test)\n",
    "y_real = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9995\n",
      "Precision :  0.9593\n",
      "Recall :  0.7712\n",
      "f1-score :  0.855\n"
     ]
    }
   ],
   "source": [
    "accuracy = round(sum(y_pred == y_real) / len(y_pred), 4)\n",
    "precision = round(sum([p == 1 & r == 1 for p, r in zip(y_pred, y_real)]) / sum(y_pred == 1), 4)\n",
    "recall = round(sum([p == 1 & r == 1 for p, r in zip(y_pred, y_real)]) / sum(y_real == 1), 4)\n",
    "f1 = round(2 / ((1/precision) + (1/recall)), 4)\n",
    "\n",
    "print('Accuracy : ', accuracy)\n",
    "print('Precision : ', precision)\n",
    "print('Recall : ', recall)\n",
    "print('f1-score : ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                1856      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 4,498\n",
      "Trainable params: 4,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0138 - accuracy: 0.9963 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 2/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 4/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 6/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9995\n",
      "Epoch 7/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9994\n",
      "Epoch 8/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 9/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 10/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 11/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 12/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 13/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0039 - val_accuracy: 0.9995\n",
      "Epoch 14/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 15/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 16/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 9.3754e-04 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 17/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 9.9943e-04 - accuracy: 0.9997 - val_loss: 0.0055 - val_accuracy: 0.9994\n",
      "Epoch 18/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 9.2846e-04 - accuracy: 0.9997 - val_loss: 0.0047 - val_accuracy: 0.9994\n",
      "Epoch 19/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 8.2300e-04 - accuracy: 0.9998 - val_loss: 0.0046 - val_accuracy: 0.9994\n",
      "Epoch 20/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 8.3575e-04 - accuracy: 0.9997 - val_loss: 0.0048 - val_accuracy: 0.9993\n",
      "Epoch 21/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 8.0625e-04 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9995\n",
      "Epoch 22/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 7.0594e-04 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "Epoch 23/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 7.0307e-04 - accuracy: 0.9997 - val_loss: 0.0051 - val_accuracy: 0.9994\n",
      "Epoch 24/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 8.4540e-04 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
      "Epoch 25/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.9155e-04 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "Epoch 26/100\n",
      "1994/1994 [==============================] - 11s 5ms/step - loss: 6.2893e-04 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9994\n",
      "Epoch 27/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 6.6716e-04 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 28/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 7.3179e-04 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9994\n",
      "Epoch 29/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 6.1192e-04 - accuracy: 0.9998 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 30/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.8926e-04 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
      "Epoch 31/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 7.0289e-04 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
      "Epoch 32/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 6.0054e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "Epoch 33/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 4.8097e-04 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "Epoch 34/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 8.3638e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 35/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.5212e-04 - accuracy: 0.9998 - val_loss: 0.0065 - val_accuracy: 0.9992\n",
      "Epoch 36/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.2750e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
      "Epoch 37/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 6.6948e-04 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9994\n",
      "Epoch 38/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.8295e-04 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9994\n",
      "Epoch 39/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.3545e-04 - accuracy: 0.9999 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.2165e-04 - accuracy: 0.9998 - val_loss: 0.0073 - val_accuracy: 0.9994\n",
      "Epoch 41/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.4183e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 42/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.7642e-04 - accuracy: 0.9998 - val_loss: 0.0060 - val_accuracy: 0.9994\n",
      "Epoch 43/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.4100e-04 - accuracy: 0.9998 - val_loss: 0.0058 - val_accuracy: 0.9994\n",
      "Epoch 44/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.4758e-04 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 5.7125e-04 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "Epoch 46/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.0545e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.7232e-04 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9994\n",
      "Epoch 48/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.9953e-04 - accuracy: 0.9999 - val_loss: 0.0084 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.8010e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 4.5274e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.1660e-04 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "1994/1994 [==============================] - 9s 4ms/step - loss: 4.3359e-04 - accuracy: 0.9998 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "Epoch 53/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.9060e-04 - accuracy: 0.9999 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "Epoch 54/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 5.6798e-04 - accuracy: 0.9998 - val_loss: 0.0063 - val_accuracy: 0.9994\n",
      "Epoch 55/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.1595e-04 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 0.9994\n",
      "Epoch 56/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.2193e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9993\n",
      "Epoch 57/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.7312e-04 - accuracy: 0.9999 - val_loss: 0.0086 - val_accuracy: 0.9995\n",
      "Epoch 58/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.5074e-04 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9994\n",
      "Epoch 59/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.4825e-04 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.4694e-04 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.9505e-04 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.3981e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 63/100\n",
      "1994/1994 [==============================] - 11s 5ms/step - loss: 3.1443e-04 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.5176e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 65/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 3.7328e-04 - accuracy: 0.9998 - val_loss: 0.0065 - val_accuracy: 0.9994\n",
      "Epoch 66/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.4114e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9994\n",
      "Epoch 67/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 4.0181e-04 - accuracy: 0.9999 - val_loss: 0.0060 - val_accuracy: 0.9993\n",
      "Epoch 68/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.1949e-04 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9994\n",
      "Epoch 69/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.5992e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 70/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.3370e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "Epoch 71/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.8178e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9994\n",
      "Epoch 72/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 2.8025e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 2.9969e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 74/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.6600e-04 - accuracy: 0.9999 - val_loss: 0.0090 - val_accuracy: 0.9994\n",
      "Epoch 75/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 2.5043e-04 - accuracy: 0.9999 - val_loss: 0.0090 - val_accuracy: 0.9994\n",
      "Epoch 76/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.5805e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9994\n",
      "Epoch 77/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 3.0652e-04 - accuracy: 0.9999 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
      "Epoch 78/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 1.9568e-04 - accuracy: 0.9999 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
      "Epoch 79/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 4.5810e-04 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 80/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 1.9927e-04 - accuracy: 0.9999 - val_loss: 0.0095 - val_accuracy: 0.9994\n",
      "Epoch 81/100\n",
      "1994/1994 [==============================] - 11s 5ms/step - loss: 3.4190e-04 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9995\n",
      "Epoch 82/100\n",
      "1994/1994 [==============================] - 9s 4ms/step - loss: 3.2581e-04 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "1994/1994 [==============================] - 9s 4ms/step - loss: 2.4099e-04 - accuracy: 0.9999 - val_loss: 0.0101 - val_accuracy: 0.9994\n",
      "Epoch 84/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.6580e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.4504e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.5410e-04 - accuracy: 0.9999 - val_loss: 0.0085 - val_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 3.4129e-04 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "1994/1994 [==============================] - 9s 5ms/step - loss: 3.2734e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.7430e-04 - accuracy: 0.9999 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
      "Epoch 90/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.2630e-04 - accuracy: 0.9999 - val_loss: 0.0098 - val_accuracy: 0.9994\n",
      "Epoch 91/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.8858e-04 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 1.9951e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
      "Epoch 93/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.2035e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9994\n",
      "Epoch 94/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.3374e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "1994/1994 [==============================] - 23s 11ms/step - loss: 1.8662e-04 - accuracy: 0.9999 - val_loss: 0.0089 - val_accuracy: 0.9994\n",
      "Epoch 96/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.9160e-04 - accuracy: 0.9999 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.5822e-04 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9994\n",
      "Epoch 98/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.3641e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9994\n",
      "Epoch 99/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 2.1770e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 100/100\n",
      "1994/1994 [==============================] - 10s 5ms/step - loss: 3.0321e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "n_inputs = x_train.shape[1]\n",
    "n_output = 2\n",
    "\n",
    "model_nn = tf.keras.Sequential([\n",
    "    layers.Dense(64, input_shape=(n_inputs, ), activation='tanh'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(n_output, activation='softmax'),\n",
    "])\n",
    "model_nn.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "model_nn.summary()\n",
    "\n",
    "# train\n",
    "model_nn.fit(x_train, y_train, batch_size=100, epochs=100,\n",
    "             validation_data=(x_test, y_test))\n",
    "\n",
    "# predict\n",
    "y_pred = model_nn.predict(x_test)\n",
    "y_real = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85290\n",
      "           1       0.91      0.73      0.81       153\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.96      0.87      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "accuracy = round(sum(y_pred == y_real) / len(y_pred), 4)\n",
    "print('Accuracy : ', accuracy)\n",
    "print(classification_report(y_real, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28480, 28)\n",
      "(28480,)\n",
      "(256327, 28)\n",
      "(256327,)\n"
     ]
    }
   ],
   "source": [
    "n_train = int(len(x_data) * 0.1)\n",
    "\n",
    "x_train = x_data[:n_train]\n",
    "y_train = y_data[:n_train]\n",
    "x_test = x_data[n_train:]\n",
    "y_test = y_data[n_train:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# (28480, 28)\n",
    "# (28480,)\n",
    "# (256327, 28)\n",
    "# (256327,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28)]              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               2900      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                5050      \n",
      "=================================================================\n",
      "Total params: 7,950\n",
      "Trainable params: 7,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 28)                2828      \n",
      "=================================================================\n",
      "Total params: 7,928\n",
      "Trainable params: 7,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "285/285 [==============================] - 7s 23ms/step - loss: 0.8719 - val_loss: 0.8146\n",
      "Epoch 2/15\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.7557 - val_loss: 0.7854\n",
      "Epoch 3/15\n",
      "285/285 [==============================] - 5s 18ms/step - loss: 0.7378 - val_loss: 0.7750\n",
      "Epoch 4/15\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.7308 - val_loss: 0.7701\n",
      "Epoch 5/15\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 0.7270 - val_loss: 0.7671\n",
      "Epoch 6/15\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 0.7246 - val_loss: 0.7650\n",
      "Epoch 7/15\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.7229 - val_loss: 0.7636\n",
      "Epoch 8/15\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 0.7217 - val_loss: 0.7623\n",
      "Epoch 9/15\n",
      "285/285 [==============================] - 5s 17ms/step - loss: 0.7206 - val_loss: 0.7614\n",
      "Epoch 10/15\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.7198 - val_loss: 0.7604\n",
      "Epoch 11/15\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.7190 - val_loss: 0.7599\n",
      "Epoch 12/15\n",
      "285/285 [==============================] - 6s 20ms/step - loss: 0.7185 - val_loss: 0.7594\n",
      "Epoch 13/15\n",
      "285/285 [==============================] - 6s 21ms/step - loss: 0.7182 - val_loss: 0.7589\n",
      "Epoch 14/15\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.7178 - val_loss: 0.7587\n",
      "Epoch 15/15\n",
      "285/285 [==============================] - 5s 19ms/step - loss: 0.7176 - val_loss: 0.7583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b29249b460>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "n_inputs = x_train.shape[1]\n",
    "n_outputs = 2\n",
    "n_latent = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(n_inputs, ))\n",
    "x = tf.keras.layers.Dense(100, activation='tanh')(inputs)\n",
    "latent = tf.keras.layers.Dense(n_latent, activation='tanh')(x)\n",
    "\n",
    "# Encoder\n",
    "encoder = tf.keras.models.Model(inputs, latent, name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = tf.keras.layers.Input(shape=(n_latent, ))\n",
    "x = tf.keras.layers.Dense(100, activation='tanh')(latent_inputs)\n",
    "outputs = tf.keras.layers.Dense(n_inputs, activation='sigmoid')(x)\n",
    "\n",
    "# Decoder\n",
    "decoder = tf.keras.models.Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# 정상 데이터 만을 학습\n",
    "x_train_norm = x_train[y_train == 0]\n",
    "\n",
    "autoencoder = tf.keras.models.Model(inputs, decoder(encoder(inputs)))\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(x_train_norm, x_train_norm, epochs=15, batch_size = 100, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                1632      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 2,194\n",
      "Trainable params: 2,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "285/285 [==============================] - 2s 5ms/step - loss: 0.0511 - accuracy: 0.9929\n",
      "Epoch 2/10\n",
      "285/285 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9989\n",
      "Epoch 3/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 5/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 6/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 7/10\n",
      "285/285 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 9/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "285/285 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2c59c94f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = encoder.predict(x_train)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    layers.Dense(32, input_dim=n_latent, activation='tanh'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(n_outputs, activation ='softmax')\n",
    "])\n",
    "classifier.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "classifier.summary()\n",
    "\n",
    "classifier.fit(encoded, y_train, batch_size=100, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
